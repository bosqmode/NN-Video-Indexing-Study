{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime\n",
    "from coco import COCO\n",
    "from coco_final_labels import labels as coco_labels\n",
    "import shutil\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib as plt\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import tensorflow_addons as tfa\n",
    "import io\n",
    "\n",
    "\n",
    "from kerasgen.balanced_image_dataset import balanced_image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 01:47:02.201742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:02.207617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:02.207767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 01:47:04.495767: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 01:47:04.496409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:04.496562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:04.496674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:04.829694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:04.829830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:04.829926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 01:47:04.830025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8902 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "LAST_DENSE = 1024\n",
    "SOFTMAX_OUT = True\n",
    "FROM_LOGITS = False\n",
    "LEARNING_RATE = 0.0001\n",
    "INFO = \"-\"\n",
    "TRAIN_IMAGES = 'data/coco_onehot_train'\n",
    "VAL_IMAGES = 'data/coco_onehot_val'\n",
    "TRANSFER_TRAIN_IMAGES ='data/transfer_train'\n",
    "TRANSFER_VAL_IMAGES = 'data/transfer_val'\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "CONFIG_STRING = \"batch_size: {0} | last_dense: {1} | softmax: {2} | from_logits: {3} | lr: {4} | info: {5}\"\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "train_files = {}\n",
    "for d in os.listdir(TRAIN_IMAGES):\n",
    "    files = os.listdir(f\"{TRAIN_IMAGES}/{d}\")\n",
    "    if len(files) > 0:\n",
    "        train_files[d] = files\n",
    "\n",
    "print(len(train_files))\n",
    "\n",
    "val_files = {}\n",
    "for d in os.listdir(VAL_IMAGES):\n",
    "    files = os.listdir(f\"{VAL_IMAGES}/{d}\")\n",
    "    if len(files) > 0:\n",
    "        val_files[d] = files\n",
    "\n",
    "print(len(val_files))\n",
    "\n",
    "transfer_train_files = {}\n",
    "for d in os.listdir(TRANSFER_TRAIN_IMAGES):\n",
    "    files = os.listdir(f\"{TRANSFER_TRAIN_IMAGES}/{d}\")\n",
    "    if len(files) > 0:\n",
    "        transfer_train_files[d] = files\n",
    "\n",
    "print(len(transfer_train_files))\n",
    "\n",
    "transfer_val_files = {}\n",
    "for d in os.listdir(TRANSFER_VAL_IMAGES):\n",
    "    files = os.listdir(f\"{TRANSFER_VAL_IMAGES}/{d}\")\n",
    "    if len(files) > 0:\n",
    "        transfer_val_files[d] = files\n",
    "\n",
    "print(len(transfer_val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image, label):\n",
    "    # image = tf.io.read_file(filename)\n",
    "    # image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = keras.applications.ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "resnet50.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,482,048\n",
      "Trainable params: 32,436,608\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(224,224,3))\n",
    "encoder = resnet50(input)\n",
    "avg_pool = GlobalAveragePooling2D()(encoder)\n",
    "fc = Dense(2048, activation=\"relu\")(avg_pool)\n",
    "fc = Dense(2048, activation=\"relu\")(fc)\n",
    "fc = Dense(256, activation=None)(fc)\n",
    "#output = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(fc)\n",
    "model = Model(input, fc)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.002),\n",
    "    loss=tfa.losses.TripletSemiHardLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 151333 files belonging to 80 classes.\n",
      "Found 16005 files belonging to 80 classes.\n"
     ]
    }
   ],
   "source": [
    "#builder = tfds.ImageFolder(root_dir='data2/')\n",
    "# print(builder.info)\n",
    "# ds = builder.as_dataset(split='coco_onehot_train', shuffle_files=True, as_supervised=True)\n",
    "#val_ds = builder.as_dataset(split='coco_onehot_val', shuffle_files=True, as_supervised=True)\n",
    "\n",
    "train_ds = balanced_image_dataset_from_directory(\n",
    "    directory='data2/coco_onehot_train',\n",
    "    image_size=(224,224),\n",
    "    validation_split=0,\n",
    "    subset=None,\n",
    "    seed=555,\n",
    "    safe_triplet=True\n",
    ")\n",
    "\n",
    "val_ds = balanced_image_dataset_from_directory(\n",
    "    directory='data2/coco_onehot_val',\n",
    "    image_size=(224,224),\n",
    "    validation_split=0,\n",
    "    subset=None,\n",
    "    seed=555,\n",
    "    safe_triplet=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(load_image)\n",
    "ds = ds.batch(32, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "weight_dir = 'weights/siamese_tripletloss/{0}'.format(current_time)\n",
    "\n",
    "weight_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=weight_dir,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 01:47:43.400977: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-08-04 01:47:43.848502: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-08-04 01:47:45.106157: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4730/4730 [==============================] - ETA: 0s - loss: 0.4830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 02:05:00.175568: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/siamese_tripletloss/20220804-014738/assets\n",
      "4730/4730 [==============================] - 1046s 220ms/step - loss: 0.4830 - val_loss: 1.6237\n",
      "Epoch 2/20\n",
      "4730/4730 [==============================] - 1028s 217ms/step - loss: 0.3802 - val_loss: 70.7245\n",
      "Epoch 3/20\n",
      "4730/4730 [==============================] - ETA: 0s - loss: 0.3664INFO:tensorflow:Assets written to: weights/siamese_tripletloss/20220804-014738/assets\n",
      "4730/4730 [==============================] - 923s 195ms/step - loss: 0.3664 - val_loss: 0.4748\n",
      "Epoch 4/20\n",
      "4730/4730 [==============================] - 906s 192ms/step - loss: 0.3498 - val_loss: 0.7974\n",
      "Epoch 5/20\n",
      "4730/4730 [==============================] - 906s 192ms/step - loss: 0.3290 - val_loss: 0.5242\n",
      "Epoch 6/20\n",
      "4730/4730 [==============================] - 907s 192ms/step - loss: 0.3172 - val_loss: 0.4823\n",
      "Epoch 7/20\n",
      "4730/4730 [==============================] - 907s 192ms/step - loss: 0.3260 - val_loss: 0.6641\n",
      "Epoch 8/20\n",
      "4730/4730 [==============================] - ETA: 0s - loss: 0.3133INFO:tensorflow:Assets written to: weights/siamese_tripletloss/20220804-014738/assets\n",
      "4730/4730 [==============================] - 918s 194ms/step - loss: 0.3133 - val_loss: 0.3921\n",
      "Epoch 9/20\n",
      "4730/4730 [==============================] - 907s 192ms/step - loss: 0.3052 - val_loss: 0.4109\n",
      "Epoch 10/20\n",
      "4730/4730 [==============================] - 907s 192ms/step - loss: 0.3064 - val_loss: 0.7366\n",
      "Epoch 11/20\n",
      "4730/4730 [==============================] - 907s 192ms/step - loss: 0.3048 - val_loss: 0.6358\n",
      "Epoch 12/20\n",
      "4730/4730 [==============================] - 908s 192ms/step - loss: 0.2910 - val_loss: 0.4967\n",
      "Epoch 13/20\n",
      "4730/4730 [==============================] - 907s 192ms/step - loss: 0.2773 - val_loss: 0.5581\n",
      "Epoch 14/20\n",
      "4730/4730 [==============================] - 908s 192ms/step - loss: 0.2833 - val_loss: 0.4539\n",
      "Epoch 15/20\n",
      "4730/4730 [==============================] - 908s 192ms/step - loss: 0.2516 - val_loss: 0.4798\n",
      "Epoch 16/20\n",
      "4730/4730 [==============================] - ETA: 0s - loss: 0.2410INFO:tensorflow:Assets written to: weights/siamese_tripletloss/20220804-014738/assets\n",
      "4730/4730 [==============================] - 918s 194ms/step - loss: 0.2410 - val_loss: 0.3904\n",
      "Epoch 17/20\n",
      "4730/4730 [==============================] - ETA: 0s - loss: 0.2302INFO:tensorflow:Assets written to: weights/siamese_tripletloss/20220804-014738/assets\n",
      "4730/4730 [==============================] - 918s 194ms/step - loss: 0.2302 - val_loss: 0.3842\n",
      "Epoch 18/20\n",
      "4730/4730 [==============================] - 908s 192ms/step - loss: 0.2148 - val_loss: 0.3922\n",
      "Epoch 19/20\n",
      "4730/4730 [==============================] - 908s 192ms/step - loss: 0.2062 - val_loss: 0.3951\n",
      "Epoch 20/20\n",
      "4730/4730 [==============================] - 914s 193ms/step - loss: 0.1937 - val_loss: 0.4024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad4c5e0eb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=20, validation_data=val_ds, callbacks=[weight_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = val_ds.map(load_image)\n",
    "val_ds = val_ds.batch(32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
    "\n",
    "out_m = io.open(\"meta.tsv\", \"w\", encoding=\"utf-8\")\n",
    "for img, labels in tfds.as_numpy(val_ds):\n",
    "    [out_m.write(str(x) + \"\\n\") for x in labels]\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 14.         16.         13.       ]\n",
      "   [ 14.         16.         13.       ]\n",
      "   [ 14.         16.         13.       ]\n",
      "   ...\n",
      "   [ 43.         37.         25.       ]\n",
      "   [ 43.         37.         25.       ]\n",
      "   [ 43.         37.         25.       ]]\n",
      "\n",
      "  [[ 20.         22.         17.       ]\n",
      "   [ 20.         22.         17.       ]\n",
      "   [ 20.         22.         17.       ]\n",
      "   ...\n",
      "   [ 76.97766    65.01117    52.97766  ]\n",
      "   [ 75.0134     65.9933     51.013397 ]\n",
      "   [ 77.         65.         53.       ]]\n",
      "\n",
      "  [[ 17.         22.         15.       ]\n",
      "   [ 17.         22.         15.       ]\n",
      "   [ 17.         22.         15.       ]\n",
      "   ...\n",
      "   [ 80.97766    59.01117    44.97766  ]\n",
      "   [ 79.0134     59.9933     43.013397 ]\n",
      "   [ 81.         59.         45.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[120.        107.         75.       ]\n",
      "   [120.        107.         75.       ]\n",
      "   [120.        107.         75.       ]\n",
      "   ...\n",
      "   [202.        208.        180.       ]\n",
      "   [202.        208.        180.       ]\n",
      "   [202.        208.        180.       ]]\n",
      "\n",
      "  [[121.        108.         74.       ]\n",
      "   [121.        108.         74.       ]\n",
      "   [121.        108.         74.       ]\n",
      "   ...\n",
      "   [201.        210.        183.       ]\n",
      "   [201.        210.        183.       ]\n",
      "   [201.        210.        183.       ]]\n",
      "\n",
      "  [[119.        106.         71.       ]\n",
      "   [119.        106.         71.       ]\n",
      "   [119.        106.         71.       ]\n",
      "   ...\n",
      "   [204.        213.        186.       ]\n",
      "   [204.        213.        186.       ]\n",
      "   [204.        213.        186.       ]]]\n",
      "\n",
      "\n",
      " [[[155.        156.        161.       ]\n",
      "   [147.        148.        153.       ]\n",
      "   [149.        148.        154.       ]\n",
      "   ...\n",
      "   [205.         95.        142.       ]\n",
      "   [203.         95.        144.       ]\n",
      "   [210.        102.        151.       ]]\n",
      "\n",
      "  [[155.        156.        161.       ]\n",
      "   [147.        148.        153.       ]\n",
      "   [149.        148.        154.       ]\n",
      "   ...\n",
      "   [205.         95.        142.       ]\n",
      "   [203.         95.        144.       ]\n",
      "   [210.        102.        151.       ]]\n",
      "\n",
      "  [[155.        156.        161.       ]\n",
      "   [147.        148.        153.       ]\n",
      "   [149.        148.        154.       ]\n",
      "   ...\n",
      "   [205.         95.        142.       ]\n",
      "   [203.         95.        144.       ]\n",
      "   [210.        102.        151.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[206.        199.        206.       ]\n",
      "   [206.        199.        206.       ]\n",
      "   [207.        200.        207.       ]\n",
      "   ...\n",
      "   [121.        107.        104.       ]\n",
      "   [123.        111.        111.       ]\n",
      "   [118.        106.        106.       ]]\n",
      "\n",
      "  [[206.        199.        206.       ]\n",
      "   [206.        199.        206.       ]\n",
      "   [207.        200.        207.       ]\n",
      "   ...\n",
      "   [121.        107.        104.       ]\n",
      "   [123.        111.        111.       ]\n",
      "   [118.        106.        106.       ]]\n",
      "\n",
      "  [[206.        199.        206.       ]\n",
      "   [206.        199.        206.       ]\n",
      "   [207.        200.        207.       ]\n",
      "   ...\n",
      "   [121.        107.        104.       ]\n",
      "   [123.        111.        111.       ]\n",
      "   [118.        106.        106.       ]]]\n",
      "\n",
      "\n",
      " [[[186.        189.        182.       ]\n",
      "   [186.        189.        182.       ]\n",
      "   [186.98885   188.01115   182.       ]\n",
      "   ...\n",
      "   [164.        162.        148.97766  ]\n",
      "   [164.0067    162.        147.       ]\n",
      "   [165.        162.        147.       ]]\n",
      "\n",
      "  [[183.        186.        179.       ]\n",
      "   [183.        186.        179.       ]\n",
      "   [183.98885   185.01115   179.       ]\n",
      "   ...\n",
      "   [155.        156.        142.       ]\n",
      "   [155.0134    155.9933    141.9866   ]\n",
      "   [157.        155.        140.       ]]\n",
      "\n",
      "  [[178.        181.        174.       ]\n",
      "   [178.        181.        174.       ]\n",
      "   [178.        181.        174.       ]\n",
      "   ...\n",
      "   [166.        168.        154.98883  ]\n",
      "   [166.        168.        154.       ]\n",
      "   [166.        168.        154.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[143.        124.        110.       ]\n",
      "   [143.        124.        110.       ]\n",
      "   [143.        124.        110.       ]\n",
      "   ...\n",
      "   [190.        191.        193.       ]\n",
      "   [190.        191.        193.       ]\n",
      "   [190.        191.        193.       ]]\n",
      "\n",
      "  [[133.        107.         94.       ]\n",
      "   [133.        107.         94.       ]\n",
      "   [133.        107.         94.       ]\n",
      "   ...\n",
      "   [189.        190.        192.       ]\n",
      "   [189.        190.        192.       ]\n",
      "   [189.        190.        192.       ]]\n",
      "\n",
      "  [[113.         85.         73.       ]\n",
      "   [113.         85.         73.       ]\n",
      "   [113.         85.         73.       ]\n",
      "   ...\n",
      "   [187.        188.        190.       ]\n",
      "   [187.        188.        190.       ]\n",
      "   [187.        188.        190.       ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[243.        229.        154.       ]\n",
      "   [227.        210.        141.       ]\n",
      "   [220.        193.        140.       ]\n",
      "   ...\n",
      "   [ 74.         47.         26.       ]\n",
      "   [ 70.         43.         24.       ]\n",
      "   [ 68.         43.         23.       ]]\n",
      "\n",
      "  [[243.        229.        154.       ]\n",
      "   [227.        210.        141.       ]\n",
      "   [220.        193.        140.       ]\n",
      "   ...\n",
      "   [ 74.         47.         26.       ]\n",
      "   [ 70.         43.         24.       ]\n",
      "   [ 68.         43.         23.       ]]\n",
      "\n",
      "  [[243.        229.        154.       ]\n",
      "   [227.        210.        141.       ]\n",
      "   [220.        193.        140.       ]\n",
      "   ...\n",
      "   [ 74.         47.         26.       ]\n",
      "   [ 70.         43.         24.       ]\n",
      "   [ 68.         43.         23.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 44.         33.         13.       ]\n",
      "   [ 20.          9.          0.       ]\n",
      "   [ 45.         30.          9.       ]\n",
      "   ...\n",
      "   [ 61.         48.          4.       ]\n",
      "   [ 59.         44.          3.       ]\n",
      "   [ 68.         50.         12.       ]]\n",
      "\n",
      "  [[ 44.         33.         13.       ]\n",
      "   [ 20.          9.          0.       ]\n",
      "   [ 45.         30.          9.       ]\n",
      "   ...\n",
      "   [ 61.         48.          4.       ]\n",
      "   [ 59.         44.          3.       ]\n",
      "   [ 68.         50.         12.       ]]\n",
      "\n",
      "  [[ 44.         33.         13.       ]\n",
      "   [ 20.          9.          0.       ]\n",
      "   [ 45.         30.          9.       ]\n",
      "   ...\n",
      "   [ 61.         48.          4.       ]\n",
      "   [ 59.         44.          3.       ]\n",
      "   [ 68.         50.         12.       ]]]\n",
      "\n",
      "\n",
      " [[[ 73.          3.          1.       ]\n",
      "   [ 73.          3.          1.       ]\n",
      "   [ 73.          3.          1.       ]\n",
      "   ...\n",
      "   [241.        191.        203.       ]\n",
      "   [241.        191.        203.       ]\n",
      "   [241.        191.        203.       ]]\n",
      "\n",
      "  [[ 72.          4.          3.       ]\n",
      "   [ 72.          4.          1.0133929]\n",
      "   [ 72.          4.          2.9776788]\n",
      "   ...\n",
      "   [244.        194.        206.       ]\n",
      "   [244.        194.        206.       ]\n",
      "   [244.        194.        206.       ]]\n",
      "\n",
      "  [[ 64.          0.          0.       ]\n",
      "   [ 64.          0.          0.       ]\n",
      "   [ 64.          0.          0.       ]\n",
      "   ...\n",
      "   [243.        193.        204.       ]\n",
      "   [243.        193.        204.       ]\n",
      "   [243.        193.        204.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[249.        185.        220.       ]\n",
      "   [247.0134    185.9933    220.       ]\n",
      "   [248.97768   185.01115   220.       ]\n",
      "   ...\n",
      "   [ 41.         11.          1.       ]\n",
      "   [ 41.         11.          1.       ]\n",
      "   [ 41.         11.          1.       ]]\n",
      "\n",
      "  [[248.        191.        224.       ]\n",
      "   [247.0067    191.9933    224.       ]\n",
      "   [247.98885   191.01115   224.       ]\n",
      "   ...\n",
      "   [ 53.         15.          4.       ]\n",
      "   [ 53.         15.          4.       ]\n",
      "   [ 53.         15.          4.       ]]\n",
      "\n",
      "  [[253.        199.        231.       ]\n",
      "   [253.        199.        231.       ]\n",
      "   [253.        199.        231.       ]\n",
      "   ...\n",
      "   [ 62.         20.          8.       ]\n",
      "   [ 62.         20.          8.       ]\n",
      "   [ 62.         20.          8.       ]]]\n",
      "\n",
      "\n",
      " [[[153.        156.        111.       ]\n",
      "   [154.9866    157.9866    112.98661  ]\n",
      "   [155.        157.01115   116.95536  ]\n",
      "   ...\n",
      "   [ 16.955322   12.955322   11.955322 ]\n",
      "   [ 12.979904    8.979904    7.979904 ]\n",
      "   [ 10.          6.          5.       ]]\n",
      "\n",
      "  [[141.        144.         99.       ]\n",
      "   [140.0067    143.0067     98.0067   ]\n",
      "   [151.86607   154.86607   111.84375  ]\n",
      "   ...\n",
      "   [ 17.966492   13.966492   12.966492 ]\n",
      "   [ 14.986603   10.986603    9.986603 ]\n",
      "   [ 13.          9.          8.       ]]\n",
      "\n",
      "  [[136.        139.         92.       ]\n",
      "   [131.03348   134.03348    89.02009  ]\n",
      "   [142.86607   145.86607   102.84375  ]\n",
      "   ...\n",
      "   [ 17.         13.         12.       ]\n",
      "   [ 16.986603   12.986603   11.986603 ]\n",
      "   [ 15.         11.         10.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83.         35.         35.       ]\n",
      "   [ 81.01339    35.         35.       ]\n",
      "   [ 81.         35.         35.       ]\n",
      "   ...\n",
      "   [ 97.04468    75.04468    54.044678 ]\n",
      "   [101.         78.979904   57.973206 ]\n",
      "   [101.         76.         54.       ]]\n",
      "\n",
      "  [[ 76.         30.         32.       ]\n",
      "   [ 76.9933     32.97991    33.986607 ]\n",
      "   [ 77.98884    33.98884    34.98884  ]\n",
      "   ...\n",
      "   [ 97.04468    75.04468    54.044678 ]\n",
      "   [101.         78.979904   57.973206 ]\n",
      "   [101.         76.         54.       ]]\n",
      "\n",
      "  [[ 76.         32.         33.       ]\n",
      "   [ 74.01339    30.013393   31.013393 ]\n",
      "   [ 69.0558     27.033482   28.033482 ]\n",
      "   ...\n",
      "   [ 97.03351    75.03351    54.03351  ]\n",
      "   [100.         77.979904   56.973206 ]\n",
      "   [100.         75.         53.       ]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.28350025,  0.14702086,  3.747245  , ..., -1.9733976 ,\n",
       "        -1.2136004 , -0.9483841 ],\n",
       "       [ 0.47213095,  0.793357  ,  2.4847436 , ..., -1.9187876 ,\n",
       "        -0.98294044, -0.6913021 ],\n",
       "       [ 0.8424904 ,  0.4827597 ,  0.9655766 , ..., -2.4185    ,\n",
       "        -1.324714  , -0.72926736],\n",
       "       ...,\n",
       "       [ 0.633972  ,  0.87617934,  0.5870922 , ..., -1.3285888 ,\n",
       "        -0.49002016, -0.6064803 ],\n",
       "       [ 0.54578656,  0.07476747,  3.7130547 , ..., -2.0527558 ,\n",
       "        -1.1251234 , -0.9045205 ],\n",
       "       [ 0.07311046,  0.12945877,  3.9565244 , ..., -1.4896568 ,\n",
       "        -1.0014912 , -0.73534906]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = next(val_ds.as_numpy_iterator())[0]\n",
    "print(input)\n",
    "\n",
    "model.predict(input)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f7689cbb1557490bb7237f90f0f73210ec72ad5d7f089fed20fb4d5142ddbe1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
