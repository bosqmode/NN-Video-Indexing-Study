{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.7.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: opencv-python in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (4.4.0.46)\n",
      "Requirement already satisfied: tensorflow_datasets in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: matplotlib in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pycocotools in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (2.0.4)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (0.37.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.19.5)\n",
      "Requirement already satisfied: six>=1.12.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (13.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (3.19.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (0.15.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (1.12)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (0.23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-gpu==2.7.0) (3.7.4.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (2.27.1)\n",
      "Requirement already satisfied: promise in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (21.4.0)\n",
      "Requirement already satisfied: tensorflow-metadata in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (1.5.0)\n",
      "Requirement already satisfied: tqdm in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (4.62.3)\n",
      "Requirement already satisfied: dill in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (5.4.0)\n",
      "Requirement already satisfied: future in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.10)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.54.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.4)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.7.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.10.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in f:\\koulu\\opparii\\projekti\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 22.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.7.0 opencv-python tensorflow_datasets matplotlib pycocotools;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime\n",
    "from coco import COCO\n",
    "from coco_labels_paper import labels as coco_labels\n",
    "import shutil\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LAST_DENSE = 1024\n",
    "SOFTMAX_OUT = True\n",
    "FROM_LOGITS = False\n",
    "LEARNING_RATE = 0.0001\n",
    "INFO = \"-\"\n",
    "\n",
    "#DATA_ROOT = \"data/coco_onehot_data\"\n",
    "DATA_ROOT = \"//bosqmode/koodit/Oppari/data/coco_onehot_data\"\n",
    "CONFIG_STRING = \"batch_size: {0} | last_dense: {1} | softmax: {2} | from_logits: {3} | lr: {4} | info: {5}\"\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " anchor (InputLayer)            [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation (InputLayer)        [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 1024)         21831936    ['anchor[0][0]',                 \n",
      "                                                                  'validation[0][0]']             \n",
      "                                                                                                  \n",
      " distance_layer (DistanceLayer)  (None, 1024)        0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            1025        ['distance_layer[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,832,961\n",
      "Trainable params: 21,817,729\n",
      "Non-trainable params: 15,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class DistanceLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, anchor, validation):\n",
    "        return tf.math.abs(anchor - validation)\n",
    "\n",
    "class ResNet34:\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.CreateFeatureExtractor()\n",
    "\n",
    "    def IdentityBlock(self, input, filters):\n",
    "        conv1 = Conv2D(filters, (3,3), padding=\"same\")(input)\n",
    "        batchnorm1 = BatchNormalization(axis=3)(conv1)\n",
    "        relu1 = ReLU()(batchnorm1)\n",
    "\n",
    "        conv2 = Conv2D(filters, (3,3), padding=\"same\")(relu1)\n",
    "        batchnorm2 = BatchNormalization(axis=3)(conv2)\n",
    "\n",
    "        add = Add()([batchnorm2,input])\n",
    "        relu2 = ReLU()(add)\n",
    "        return relu2\n",
    "\n",
    "    def ConvolutionBlock(self, input, filters):\n",
    "        conv1 = Conv2D(filters, (3,3), padding=\"same\", strides=(2,2))(input)\n",
    "        batchnorm1 = BatchNormalization(axis=3)(conv1)\n",
    "        relu1 = ReLU()(batchnorm1)\n",
    "\n",
    "        conv2 = Conv2D(filters, (3,3), padding=\"same\")(relu1)\n",
    "        batchnorm2 = BatchNormalization(axis=3)(conv2)\n",
    "\n",
    "        linear_proj = Conv2D(filters, (1,1), strides=(2,2))(input)\n",
    "\n",
    "        add = Add()([batchnorm2, linear_proj])\n",
    "        relu2 = ReLU()(add)\n",
    "        return relu2\n",
    "\n",
    "    def CreateFeatureExtractor(self):\n",
    "        input = Input(shape=self.input_shape)\n",
    "        x = ZeroPadding2D((3,3))(input)\n",
    "        x = Conv2D(64, (7,7), strides=(2,2))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = MaxPool2D(pool_size=(3,3), strides=2, padding=\"same\")(x)\n",
    "\n",
    "        x = self.IdentityBlock(x, 64)\n",
    "        x = self.IdentityBlock(x, 64)\n",
    "        x = self.IdentityBlock(x, 64)\n",
    "        x = self.ConvolutionBlock(x, 128)\n",
    "        x = self.IdentityBlock(x, 128)\n",
    "        x = self.IdentityBlock(x, 128)\n",
    "        x = self.IdentityBlock(x, 128)\n",
    "        x = self.ConvolutionBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.ConvolutionBlock(x, 512)\n",
    "        x = self.IdentityBlock(x, 512)\n",
    "        x = self.IdentityBlock(x, 512)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(LAST_DENSE, activation=\"relu\")(x)\n",
    "        return Model(inputs=[input], outputs=[x], name='embedding')\n",
    "\n",
    "\n",
    "def SiameseNetwork(input_shape, embedding):\n",
    "    anchor = Input(name='anchor', shape=input_shape)\n",
    "    validation = Input(name='validation', shape=input_shape)\n",
    "\n",
    "    distances = DistanceLayer()(embedding(anchor),embedding(validation))\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    siamese_network = Model(inputs=[anchor, validation], outputs=classifier)\n",
    "    return siamese_network\n",
    "\n",
    "\n",
    "feature_extractor = ResNet34()\n",
    "siamese_network = SiameseNetwork((224,224,3), feature_extractor.model)\n",
    "siamese_network.compile(optimizer=Adam(0.0001))\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = None\n",
    "negatives = None\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for c in coco_labels:\n",
    "    if len(os.listdir(f'{DATA_ROOT}/{c}')) > 0:\n",
    "        files = tf.data.Dataset.list_files(f'{DATA_ROOT}/{c}/*', shuffle=True, seed=12345).take(-1)\n",
    "        datasets[c] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "500 : 500 : 500\n",
      "bicycle\n",
      "500 : 500 : 500\n",
      "car\n",
      "500 : 500 : 500\n",
      "motorcycle\n",
      "500 : 500 : 500\n",
      "airplane\n",
      "500 : 500 : 500\n",
      "bus\n",
      "500 : 500 : 500\n",
      "train\n",
      "500 : 500 : 500\n",
      "truck\n",
      "500 : 500 : 500\n",
      "boat\n",
      "500 : 500 : 500\n",
      "traffic light\n",
      "500 : 500 : 500\n",
      "fire hydrant\n",
      "500 : 500 : 500\n",
      "stop sign\n",
      "500 : 500 : 500\n",
      "parking meter\n",
      "500 : 500 : 500\n",
      "bench\n",
      "500 : 500 : 500\n",
      "bird\n",
      "500 : 500 : 500\n",
      "cat\n",
      "500 : 500 : 500\n",
      "dog\n",
      "500 : 500 : 500\n",
      "horse\n",
      "500 : 500 : 500\n",
      "sheep\n",
      "500 : 500 : 500\n",
      "cow\n",
      "500 : 500 : 500\n",
      "elephant\n",
      "500 : 500 : 500\n",
      "bear\n",
      "500 : 500 : 500\n",
      "zebra\n",
      "500 : 500 : 500\n",
      "giraffe\n",
      "500 : 500 : 500\n",
      "backpack\n",
      "500 : 500 : 500\n",
      "umbrella\n",
      "500 : 500 : 500\n",
      "handbag\n",
      "500 : 500 : 500\n",
      "tie\n",
      "500 : 500 : 500\n",
      "suitcase\n",
      "500 : 500 : 500\n",
      "frisbee\n",
      "500 : 500 : 500\n",
      "skis\n",
      "500 : 500 : 500\n",
      "snowboard\n",
      "500 : 500 : 500\n",
      "sports ball\n",
      "500 : 500 : 500\n",
      "kite\n",
      "500 : 500 : 500\n",
      "baseball bat\n",
      "500 : 500 : 500\n",
      "baseball glove\n",
      "500 : 500 : 500\n",
      "skateboard\n",
      "500 : 500 : 500\n",
      "surfboard\n",
      "500 : 500 : 500\n",
      "tennis racket\n",
      "500 : 500 : 500\n",
      "bottle\n",
      "500 : 500 : 500\n",
      "wine glass\n",
      "500 : 500 : 500\n",
      "cup\n",
      "500 : 500 : 500\n",
      "fork\n",
      "500 : 500 : 500\n",
      "knife\n",
      "500 : 500 : 500\n",
      "spoon\n",
      "500 : 500 : 500\n",
      "bowl\n",
      "500 : 500 : 500\n",
      "banana\n",
      "500 : 500 : 500\n",
      "apple\n",
      "500 : 500 : 500\n",
      "sandwich\n",
      "500 : 500 : 500\n",
      "orange\n",
      "500 : 500 : 500\n",
      "broccoli\n",
      "500 : 500 : 500\n",
      "carrot\n",
      "500 : 500 : 500\n",
      "hot dog\n",
      "500 : 500 : 500\n",
      "pizza\n",
      "500 : 500 : 500\n",
      "donut\n",
      "500 : 500 : 500\n",
      "cake\n",
      "500 : 500 : 500\n",
      "chair\n",
      "500 : 500 : 500\n",
      "couch\n",
      "500 : 500 : 500\n",
      "potted plant\n",
      "500 : 500 : 500\n",
      "bed\n",
      "500 : 500 : 500\n",
      "dining table\n",
      "500 : 500 : 500\n",
      "toilet\n",
      "500 : 500 : 500\n",
      "tv\n",
      "500 : 500 : 500\n",
      "laptop\n",
      "500 : 500 : 500\n",
      "mouse\n",
      "500 : 500 : 500\n",
      "remote\n",
      "500 : 500 : 500\n",
      "keyboard\n",
      "500 : 500 : 500\n",
      "cell phone\n",
      "500 : 500 : 500\n",
      "microwave\n",
      "500 : 500 : 500\n",
      "oven\n",
      "500 : 500 : 500\n",
      "toaster\n",
      "500 : 500 : 500\n",
      "sink\n",
      "500 : 500 : 500\n",
      "refrigerator\n",
      "500 : 500 : 500\n",
      "book\n",
      "500 : 500 : 500\n",
      "clock\n",
      "500 : 500 : 500\n",
      "vase\n",
      "500 : 500 : 500\n",
      "scissors\n",
      "500 : 500 : 500\n",
      "teddy bear\n",
      "500 : 500 : 500\n",
      "hair drier\n",
      "500 : 500 : 500\n",
      "toothbrush\n",
      "500 : 500 : 500\n",
      "Positives: 40000\n",
      "Negatives: 40000\n",
      "Final data: 80000\n"
     ]
    }
   ],
   "source": [
    "for key, val in datasets.items():\n",
    "    print(key)\n",
    "    files = val.take(1000)\n",
    "    half = int(len(files)/2)\n",
    "    a = files.take(half)\n",
    "    b = files.skip(half).take(half)\n",
    "    c = None\n",
    "\n",
    "    iterator = cycle(datasets.keys())\n",
    "    for i in iterator:\n",
    "        if c is None:\n",
    "            c = datasets[i].take(10)\n",
    "        else:\n",
    "            c = c.concatenate(datasets[i].take(10))\n",
    "\n",
    "        if len(c) >= half:\n",
    "            break\n",
    "        \n",
    "    print(f'{len(a)} : {len(b)} : {len(c)}')\n",
    "\n",
    "    if positives is None:\n",
    "        positives = tf.data.Dataset.zip((a, b, tf.data.Dataset.from_tensor_slices(tf.ones(len(a)))))\n",
    "        negatives = tf.data.Dataset.zip((a, c, tf.data.Dataset.from_tensor_slices(tf.zeros(len(a)))))\n",
    "    else:\n",
    "        positives = positives.concatenate(tf.data.Dataset.zip((a, b, tf.data.Dataset.from_tensor_slices(tf.ones(len(a))))))\n",
    "        negatives = negatives.concatenate(tf.data.Dataset.zip((a, c, tf.data.Dataset.from_tensor_slices(tf.zeros(len(a))))))\n",
    "\n",
    "print(f'Positives: {len(positives)}')\n",
    "print(f'Negatives: {len(negatives)}')\n",
    "\n",
    "final_data = positives.concatenate(negatives)\n",
    "print(f'Final data: {len(final_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (224,224))\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_twins(anchor, validation, label):\n",
    "    return (load_images(anchor), load_images(validation), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = final_data.map(preprocess_twins)\n",
    "processed_data = processed_data.cache()\n",
    "processed_data = processed_data.shuffle(buffer_size=len(processed_data))\n",
    "\n",
    "train_data = processed_data.take(round(len(processed_data)*.8))\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "test_data = processed_data.skip(round(len(processed_data)*.8))\n",
    "test_data = test_data.take(round(len(processed_data)*.2))\n",
    "test_data = test_data.batch(BATCH_SIZE)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t[1][0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = next(iter(train_data))\n",
    "\n",
    "fig = plt.pyplot.figure(figsize=(9,9))\n",
    "axs = fig.subplots(2,2)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i, 0].imshow(img_batch[i][0])\n",
    "    axs[i, 1].imshow(img_batch[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 35256), started 0:18:20 ago. (Use '!kill 35256' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7dae0d944f5f0eac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7dae0d944f5f0eac\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/siamese\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/siamese/{0}'.format(current_time)\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "summary_writer.set_as_default()\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, update_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_network(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_network.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_network.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_network.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "1370/4000 [=========>....................] - ETA: 59:29"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "\n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.model.save_weights(os.path.join(weight_dir, weight_file.format(\"_onehot\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 151ms/step - loss: 2.2457 - accuracy: 0.6529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2457149028778076, 0.6528735756874084]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet.model.evaluate(validation_ds, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "654d1341d31113e9d6d85a7e7f39f0df972d16b89bb726a48ebf618e1b5b3b7d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
