{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.8.0\n",
      "  Using cached tensorflow_gpu-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 158 kB/s eta 0:00:01\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/tensorflow-datasets/\u001b[0m\n",
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 127 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 605 kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.8/site-packages (from tensorflow-gpu==2.8.0) (1.16.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.8/site-packages (from tensorflow-gpu==2.8.0) (44.0.0)\n",
      "Processing /home/bosqnux/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.7.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 829 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.6.0-py3-none-any.whl (28 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.63.1-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.19.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.31.2-py3-none-any.whl (899 kB)\n",
      "\u001b[K     |████████████████████████████████| 899 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 4.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.56.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=3.1.0; python_version < \"3.10\"\n",
      "  Using cached zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "\u001b[K     |████████████████████████████████| 149 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 4.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pycocotools, promise\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp38-cp38-linux_x86_64.whl size=418830 sha256=d697131a1a276a6728149ad11664b8a777b1d10128f9329cc86ba98c7c5bbd71\n",
      "  Stored in directory: /home/bosqnux/.cache/pip/wheels/dd/e2/43/3e93cd653b3346b3d702bb0509bc611189f95d60407bff1484\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/bosqnux/Koodit/Oppari/.venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-30bcuhe4/promise/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-30bcuhe4/promise/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-geoei4ps\n",
      "       cwd: /tmp/pip-install-30bcuhe4/promise/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for promise\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for promise\n",
      "Successfully built pycocotools\n",
      "Failed to build promise\n",
      "Installing collected packages: pyasn1, rsa, cachetools, pyasn1-modules, google-auth, zipp, importlib-metadata, markdown, grpcio, numpy, protobuf, tensorboard-data-server, certifi, urllib3, charset-normalizer, idna, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, wheel, werkzeug, absl-py, tensorboard-plugin-wit, tensorboard, gast, tf-estimator-nightly, tensorflow-io-gcs-filesystem, h5py, typing-extensions, keras, astunparse, keras-preprocessing, flatbuffers, wrapt, libclang, google-pasta, termcolor, opt-einsum, tensorflow-gpu, opencv-python, googleapis-common-protos, tensorflow-metadata, promise, importlib-resources, tqdm, dill, tensorflow-datasets, fonttools, pyparsing, cycler, pillow, packaging, kiwisolver, matplotlib, pycocotools\n",
      "    Running setup.py install for promise ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 certifi-2021.10.8 charset-normalizer-2.0.12 cycler-0.11.0 dill-0.3.4 flatbuffers-2.0 fonttools-4.31.2 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.56.0 grpcio-1.44.0 h5py-3.6.0 idna-3.3 importlib-metadata-4.11.3 importlib-resources-5.6.0 keras-2.8.0 keras-preprocessing-1.1.2 kiwisolver-1.4.1 libclang-13.0.0 markdown-3.3.6 matplotlib-3.5.1 numpy-1.22.3 oauthlib-3.2.0 opencv-python-4.5.5.64 opt-einsum-3.3.0 packaging-21.3 pillow-9.0.1 promise-2.3 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.4 pyparsing-3.0.7 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-datasets-4.5.2 tensorflow-gpu-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 tensorflow-metadata-1.7.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 tqdm-4.63.1 typing-extensions-4.1.1 urllib3-1.26.9 werkzeug-2.0.3 wheel-0.37.1 wrapt-1.14.0 zipp-3.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.8.0 opencv-python tensorflow_datasets matplotlib pycocotools;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime\n",
    "from coco import COCO\n",
    "from coco_labels_paper import labels as coco_labels\n",
    "import shutil\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 06:58:57.619888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:58:57.635788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:58:57.635902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 06:59:05.332000: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-28 06:59:05.332681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:59:05.332860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:59:05.332985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:59:05.704350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:59:05.704503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:59:05.704602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-28 06:59:05.704826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9940 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "LAST_DENSE = 1024\n",
    "SOFTMAX_OUT = True\n",
    "FROM_LOGITS = False\n",
    "LEARNING_RATE = 0.0001\n",
    "INFO = \"-\"\n",
    "\n",
    "DATA_ROOT = \"data/coco_onehot_data\"\n",
    "#DATA_ROOT = \"//bosqmode/koodit/Oppari/data/coco_onehot_data\"\n",
    "CONFIG_STRING = \"batch_size: {0} | last_dense: {1} | softmax: {2} | from_logits: {3} | lr: {4} | info: {5}\"\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " anchor (InputLayer)            [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation (InputLayer)        [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 1024)         21831936    ['anchor[0][0]',                 \n",
      "                                                                  'validation[0][0]']             \n",
      "                                                                                                  \n",
      " distance_layer (DistanceLayer)  (None, 1024)        0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            1025        ['distance_layer[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,832,961\n",
      "Trainable params: 21,817,729\n",
      "Non-trainable params: 15,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class DistanceLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, anchor, validation):\n",
    "        return tf.math.abs(anchor - validation)\n",
    "\n",
    "class ResNet34:\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.CreateFeatureExtractor()\n",
    "\n",
    "    def IdentityBlock(self, input, filters):\n",
    "        conv1 = Conv2D(filters, (3,3), padding=\"same\")(input)\n",
    "        batchnorm1 = BatchNormalization(axis=3)(conv1)\n",
    "        relu1 = ReLU()(batchnorm1)\n",
    "\n",
    "        conv2 = Conv2D(filters, (3,3), padding=\"same\")(relu1)\n",
    "        batchnorm2 = BatchNormalization(axis=3)(conv2)\n",
    "\n",
    "        add = Add()([batchnorm2,input])\n",
    "        relu2 = ReLU()(add)\n",
    "        return relu2\n",
    "\n",
    "    def ConvolutionBlock(self, input, filters):\n",
    "        conv1 = Conv2D(filters, (3,3), padding=\"same\", strides=(2,2))(input)\n",
    "        batchnorm1 = BatchNormalization(axis=3)(conv1)\n",
    "        relu1 = ReLU()(batchnorm1)\n",
    "\n",
    "        conv2 = Conv2D(filters, (3,3), padding=\"same\")(relu1)\n",
    "        batchnorm2 = BatchNormalization(axis=3)(conv2)\n",
    "\n",
    "        linear_proj = Conv2D(filters, (1,1), strides=(2,2))(input)\n",
    "\n",
    "        add = Add()([batchnorm2, linear_proj])\n",
    "        relu2 = ReLU()(add)\n",
    "        return relu2\n",
    "\n",
    "    def CreateFeatureExtractor(self):\n",
    "        input = Input(shape=self.input_shape)\n",
    "        x = ZeroPadding2D((3,3))(input)\n",
    "        x = Conv2D(64, (7,7), strides=(2,2))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = MaxPool2D(pool_size=(3,3), strides=2, padding=\"same\")(x)\n",
    "\n",
    "        x = self.IdentityBlock(x, 64)\n",
    "        x = self.IdentityBlock(x, 64)\n",
    "        x = self.IdentityBlock(x, 64)\n",
    "        x = self.ConvolutionBlock(x, 128)\n",
    "        x = self.IdentityBlock(x, 128)\n",
    "        x = self.IdentityBlock(x, 128)\n",
    "        x = self.IdentityBlock(x, 128)\n",
    "        x = self.ConvolutionBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.IdentityBlock(x, 256)\n",
    "        x = self.ConvolutionBlock(x, 512)\n",
    "        x = self.IdentityBlock(x, 512)\n",
    "        x = self.IdentityBlock(x, 512)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(LAST_DENSE, activation=\"relu\")(x)\n",
    "        return Model(inputs=[input], outputs=[x], name='embedding')\n",
    "\n",
    "\n",
    "def SiameseNetwork(input_shape, embedding):\n",
    "    anchor = Input(name='anchor', shape=input_shape)\n",
    "    validation = Input(name='validation', shape=input_shape)\n",
    "\n",
    "    distances = DistanceLayer()(embedding(anchor),embedding(validation))\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    siamese_network = Model(inputs=[anchor, validation], outputs=classifier)\n",
    "    return siamese_network\n",
    "\n",
    "\n",
    "feature_extractor = ResNet34()\n",
    "siamese_network = SiameseNetwork((224,224,3), feature_extractor.model)\n",
    "siamese_network.compile(optimizer=Adam(0.0001))\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '//bosqmode/koodit/Oppari/data/coco_onehot_data/person'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bosqnux/Koodit/Oppari/Siamese.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bosqnux/Koodit/Oppari/Siamese.ipynb#ch0000005?line=3'>4</a>\u001b[0m datasets \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bosqnux/Koodit/Oppari/Siamese.ipynb#ch0000005?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m coco_labels:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bosqnux/Koodit/Oppari/Siamese.ipynb#ch0000005?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mDATA_ROOT\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mc\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bosqnux/Koodit/Oppari/Siamese.ipynb#ch0000005?line=7'>8</a>\u001b[0m         files \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mlist_files(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mDATA_ROOT\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m}\u001b[39;00m\u001b[39m/*\u001b[39m\u001b[39m'\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, seed\u001b[39m=\u001b[39m\u001b[39m12345\u001b[39m)\u001b[39m.\u001b[39mtake(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bosqnux/Koodit/Oppari/Siamese.ipynb#ch0000005?line=8'>9</a>\u001b[0m         datasets[c] \u001b[39m=\u001b[39m files\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '//bosqmode/koodit/Oppari/data/coco_onehot_data/person'"
     ]
    }
   ],
   "source": [
    "positives = None\n",
    "negatives = None\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for c in coco_labels:\n",
    "    if len(os.listdir(f'{DATA_ROOT}/{c}')) > 0:\n",
    "        files = tf.data.Dataset.list_files(f'{DATA_ROOT}/{c}/*', shuffle=True, seed=12345).take(-1)\n",
    "        datasets[c] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "500 : 500 : 500\n",
      "bicycle\n",
      "500 : 500 : 500\n",
      "car\n",
      "500 : 500 : 500\n",
      "motorcycle\n",
      "500 : 500 : 500\n",
      "airplane\n",
      "500 : 500 : 500\n",
      "bus\n",
      "500 : 500 : 500\n",
      "train\n",
      "500 : 500 : 500\n",
      "truck\n",
      "500 : 500 : 500\n",
      "boat\n",
      "500 : 500 : 500\n",
      "traffic light\n",
      "500 : 500 : 500\n",
      "fire hydrant\n",
      "500 : 500 : 500\n",
      "stop sign\n",
      "500 : 500 : 500\n",
      "parking meter\n",
      "500 : 500 : 500\n",
      "bench\n",
      "500 : 500 : 500\n",
      "bird\n",
      "500 : 500 : 500\n",
      "cat\n",
      "500 : 500 : 500\n",
      "dog\n",
      "500 : 500 : 500\n",
      "horse\n",
      "500 : 500 : 500\n",
      "sheep\n",
      "500 : 500 : 500\n",
      "cow\n",
      "500 : 500 : 500\n",
      "elephant\n",
      "500 : 500 : 500\n",
      "bear\n",
      "500 : 500 : 500\n",
      "zebra\n",
      "500 : 500 : 500\n",
      "giraffe\n",
      "500 : 500 : 500\n",
      "backpack\n",
      "500 : 500 : 500\n",
      "umbrella\n",
      "500 : 500 : 500\n",
      "handbag\n",
      "500 : 500 : 500\n",
      "tie\n",
      "500 : 500 : 500\n",
      "suitcase\n",
      "500 : 500 : 500\n",
      "frisbee\n",
      "500 : 500 : 500\n",
      "skis\n",
      "500 : 500 : 500\n",
      "snowboard\n",
      "500 : 500 : 500\n",
      "sports ball\n",
      "500 : 500 : 500\n",
      "kite\n",
      "500 : 500 : 500\n",
      "baseball bat\n",
      "500 : 500 : 500\n",
      "baseball glove\n",
      "500 : 500 : 500\n",
      "skateboard\n",
      "500 : 500 : 500\n",
      "surfboard\n",
      "500 : 500 : 500\n",
      "tennis racket\n",
      "500 : 500 : 500\n",
      "bottle\n",
      "500 : 500 : 500\n",
      "wine glass\n",
      "500 : 500 : 500\n",
      "cup\n",
      "500 : 500 : 500\n",
      "fork\n",
      "500 : 500 : 500\n",
      "knife\n",
      "500 : 500 : 500\n",
      "spoon\n",
      "500 : 500 : 500\n",
      "bowl\n",
      "500 : 500 : 500\n",
      "banana\n",
      "500 : 500 : 500\n",
      "apple\n",
      "500 : 500 : 500\n",
      "sandwich\n",
      "500 : 500 : 500\n",
      "orange\n",
      "500 : 500 : 500\n",
      "broccoli\n",
      "500 : 500 : 500\n",
      "carrot\n",
      "500 : 500 : 500\n",
      "hot dog\n",
      "500 : 500 : 500\n",
      "pizza\n",
      "500 : 500 : 500\n",
      "donut\n",
      "500 : 500 : 500\n",
      "cake\n",
      "500 : 500 : 500\n",
      "chair\n",
      "500 : 500 : 500\n",
      "couch\n",
      "500 : 500 : 500\n",
      "potted plant\n",
      "500 : 500 : 500\n",
      "bed\n",
      "500 : 500 : 500\n",
      "dining table\n",
      "500 : 500 : 500\n",
      "toilet\n",
      "500 : 500 : 500\n",
      "tv\n",
      "500 : 500 : 500\n",
      "laptop\n",
      "500 : 500 : 500\n",
      "mouse\n",
      "500 : 500 : 500\n",
      "remote\n",
      "500 : 500 : 500\n",
      "keyboard\n",
      "500 : 500 : 500\n",
      "cell phone\n",
      "500 : 500 : 500\n",
      "microwave\n",
      "500 : 500 : 500\n",
      "oven\n",
      "500 : 500 : 500\n",
      "toaster\n",
      "500 : 500 : 500\n",
      "sink\n",
      "500 : 500 : 500\n",
      "refrigerator\n",
      "500 : 500 : 500\n",
      "book\n",
      "500 : 500 : 500\n",
      "clock\n",
      "500 : 500 : 500\n",
      "vase\n",
      "500 : 500 : 500\n",
      "scissors\n",
      "500 : 500 : 500\n",
      "teddy bear\n",
      "500 : 500 : 500\n",
      "hair drier\n",
      "500 : 500 : 500\n",
      "toothbrush\n",
      "500 : 500 : 500\n",
      "Positives: 40000\n",
      "Negatives: 40000\n",
      "Final data: 80000\n"
     ]
    }
   ],
   "source": [
    "for key, val in datasets.items():\n",
    "    print(key)\n",
    "    files = val.take(1000)\n",
    "    half = int(len(files)/2)\n",
    "    a = files.take(half)\n",
    "    b = files.skip(half).take(half)\n",
    "    c = None\n",
    "\n",
    "    iterator = cycle(datasets.keys())\n",
    "    for i in iterator:\n",
    "        if c is None:\n",
    "            c = datasets[i].take(10)\n",
    "        else:\n",
    "            c = c.concatenate(datasets[i].take(10))\n",
    "\n",
    "        if len(c) >= half:\n",
    "            break\n",
    "        \n",
    "    print(f'{len(a)} : {len(b)} : {len(c)}')\n",
    "\n",
    "    if positives is None:\n",
    "        positives = tf.data.Dataset.zip((a, b, tf.data.Dataset.from_tensor_slices(tf.ones(len(a)))))\n",
    "        negatives = tf.data.Dataset.zip((a, c, tf.data.Dataset.from_tensor_slices(tf.zeros(len(a)))))\n",
    "    else:\n",
    "        positives = positives.concatenate(tf.data.Dataset.zip((a, b, tf.data.Dataset.from_tensor_slices(tf.ones(len(a))))))\n",
    "        negatives = negatives.concatenate(tf.data.Dataset.zip((a, c, tf.data.Dataset.from_tensor_slices(tf.zeros(len(a))))))\n",
    "\n",
    "print(f'Positives: {len(positives)}')\n",
    "print(f'Negatives: {len(negatives)}')\n",
    "\n",
    "final_data = positives.concatenate(negatives)\n",
    "print(f'Final data: {len(final_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (224,224))\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_twins(anchor, validation, label):\n",
    "    return (load_images(anchor), load_images(validation), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = final_data.map(preprocess_twins)\n",
    "processed_data = processed_data.cache()\n",
    "processed_data = processed_data.shuffle(buffer_size=len(processed_data))\n",
    "\n",
    "train_data = processed_data.take(round(len(processed_data)*.8))\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "test_data = processed_data.skip(round(len(processed_data)*.8))\n",
    "test_data = test_data.take(round(len(processed_data)*.2))\n",
    "test_data = test_data.batch(BATCH_SIZE)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t[1][0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = next(iter(train_data))\n",
    "\n",
    "fig = plt.pyplot.figure(figsize=(9,9))\n",
    "axs = fig.subplots(2,2)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i, 0].imshow(img_batch[i][0])\n",
    "    axs[i, 1].imshow(img_batch[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 35256), started 0:18:20 ago. (Use '!kill 35256' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7dae0d944f5f0eac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7dae0d944f5f0eac\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/siamese\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/siamese/{0}'.format(current_time)\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "summary_writer.set_as_default()\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, update_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_network(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_network.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_network.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_network.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "1370/4000 [=========>....................] - ETA: 59:29"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "\n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.model.save_weights(os.path.join(weight_dir, weight_file.format(\"_onehot\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 151ms/step - loss: 2.2457 - accuracy: 0.6529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2457149028778076, 0.6528735756874084]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet.model.evaluate(validation_ds, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "654d1341d31113e9d6d85a7e7f39f0df972d16b89bb726a48ebf618e1b5b3b7d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
